---
title: "Main"
author: "Fall2019-proj3-grp7"
output:
  pdf_document: default
---
In your final repo, there should be an R markdown file that organizes **all computational steps** for evaluating your proposed Facial Expression Recognition framework. 

This file is currently a template for running evaluation experiments. You should update it according to your codes but following precisely the same structure. 

```{r message=FALSE}
if(!require("EBImage")){
  source("https://bioconductor.org/biocLite.R")
  biocLite("EBImage")
}
if(!require("R.matlab")){
  install.packages("R.matlab")
}
if(!require("readxl")){
  install.packages("readxl")
}

if(!require("dplyr")){
  install.packages("dplyr")
}
if(!require("readxl")){
  install.packages("readxl")
}

if(!require("ggplot2")){
  install.packages("ggplot2")
}

if(!require("caret")){
  install.packages("caret")
}


if(!require("OpenImageR")){
  install.packages("OpenImageR")
}

if(!require("FSelectorRcpp")){
  install.packages("FSelectorRcpp")
}

if(!require("mlr")){
  install.packages("mlr")
}

if(!require("kernlab")){
  install.packages("kernlab")
}

if(!require("gbm")){
  install.packages("gbm")
}

if(!require("class")){
  install.packages("class")
}
if(!require("MASS")){
  install.packages("MASS")
}
if(!require("e1071")){
  install.packages("e1071")
}
library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)
library(OpenImageR)
library(FSelectorRcpp)
library(mlr)
library(kernlab)
library(gbm)
library(class)

library("e1071")
library("MASS")
```

### Step 0 set work directories, extract paths, summarize
```{r wkdir, eval=FALSE}
set.seed(0)
# setwd("~/Desktop/5243/Project 3/fall2019-proj3-sec2--grp7-master/doc")
# here replace it with your own path or manually set it in RStudio to where this rmd file is located. 
# use relative path for reproducibility
# setwd("../doc")
```

Provide directories for training images. Training images and Training fiducial points will be in different subfolders. 
```{r}
train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="") 

```


### Step 1: set up controls for evaluation experiments.

In this chunk, we have a set of controls for the evaluation experiments. 

+ (T/F) cross-validation on the training set
+ (number) K, the number of CV folds
+ (T/F) process features for training set
+ (T/F) run evaluation on an independent test set
+ (T/F) process features for test set

```{r exp_setup}
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=FALSE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
run.feature.test.test=FALSE # process features for test_test set
```
Using cross-validation or independent test set evaluation, we compare the performance of models with different specifications. In this Starter Code, we tune parameter k (number of neighbours) for KNN.

```{r model_setup_false, include=F}
k = c(5,11,21,31,41,51)
model_labels = paste("KNN with K =", k)
```

### Step 2: import data and train-test split 
```{r}
#train-test split
info <- read.csv(train_label_path)
n <- nrow(info)
n_train <- round(n*(4/5), 0)
train_idx <- sample(info$Index, n_train, replace = F)
test_idx <- setdiff(info$Index,train_idx)
```

If you choose to extract features from images, such as using Gabor filter, R memory will exhaust all images are read together. The solution is to repeat reading a smaller batch(e.g 100) and process them. 
```{r}
n_files <- length(list.files(train_image_dir))

image_list <- list()
for(i in 1:100){
   image_list[[i]] <- readImage(paste0(train_image_dir, sprintf("%04d", i), ".jpg"))
}
```

Fiducial points are stored in matlab format. In this step, we read them and store them in a list.
```{r read fiducial points}
#function to read fiducial points
#input: index
#output: matrix of fiducial points corresponding to the index
readMat.matrix <- function(index){
     return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}

#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
save(fiducial_pt_list, file="../output/fiducial_pt_list.RData")
```

### Step 3: feature selection


`feature.R` should be the wrapper for all your feature engineering functions and options. The function `feature( )` should have options that correspond to different scenarios for your project and produces an R object that contains features and responses that are required by all the models you are going to evaluate later. 
  
  + `feature.R`
  + Input: list of images or fiducial point
  + Output: an RData file that contains extracted features and corresponding responses

```{r feature}
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
  ## Distance calculation
  tm_feature_train <- system.time(dat_train <- feature_train(fiducial_pt_list, train_idx))
  dat_train <- cbind(dat_train, as.factor(info$emotion_idx[train_idx]))
  colnames(dat_train)[dim(dat_train)[2]] <- "emotion_idx"
  dat_train <- as.data.frame(dat_train)
  colnames(dat_train)<-make.names(colnames(dat_train),unique=T)

  ## Normalize
  tm_feature_train <- tm_feature_train + 
    system.time(dat_train_stand <- feature_normalization(dat_train[,c(-dim(dat_train)[2])]))
 dat_train_stand <- cbind(dat_train_stand,dat_train$emotion_idx)
 colnames(dat_train_stand)[dim(dat_train_stand)[2]] <- "emotion_idx"
 
  ## Feature selection
  tm_feature_train <- tm_feature_train + 
    system.time(feature_name <- feature_selection(dat_train_stand,"emotion_idx"))
  dat_train_selected <- dat_train[,feature_name]
  
  ## Calculate size from all selected distance
  tm_feature_train <- tm_feature_train + 
    system.time(dat_train_double <- feature_selection_size(dat_train_selected))
  
  ## Add manually selected feature
  tm_feature_train <- tm_feature_train + 
    system.time(dat_train_ratio <- manually_feature(fiducial_pt_list, train_idx))
  
  dat_train_selected_stand <- cbind(dat_train_selected,dat_train_double,dat_train_ratio)
  dat_train_selected_stand <- feature_normalization(dat_train_selected_stand)
  dat_train_selected_stand <- cbind(dat_train_selected_stand,dat_train$emotion_idx)
  colnames(dat_train_selected_stand)[dim(dat_train_selected_stand)[2]] <- "emotion_idx"
  
}

tm_feature_test <- NA
if(run.feature.test){
  ## This is the result from test
  
  feature_name <- c("point.7.to.point.21","point.10.to.point.13","point.10.to.point.33",
                    "point.11.to.point.49","point.12.to.point.55","point.14.to.point.18",
                    "point.23.to.point.50","point.34.to.point.46","point.50.to.point.62",
                    "point.59.to.point.62")
  
  ## Distance Feature
  tm_feature_test <- system.time(dat_test <- feature_train(fiducial_pt_list, test_idx))
  dat_test <- cbind(dat_test, as.factor(info$emotion_idx[test_idx]))
  colnames(dat_test)[dim(dat_test)[2]] <- "emotion_idx"
  dat_test <- as.data.frame(dat_test)
  colnames(dat_test)<-make.names(colnames(dat_test),unique=T)
  dat_test_selected <- dat_test[,feature_name]
  
  ## Size Feature
  tm_feature_test <- tm_feature_test +
    system.time(dat_test_double <- feature_selection_size(dat_test_selected))
  
  ## Add manually selected feature
  tm_feature_test <- tm_feature_test + 
    system.time(dat_test_ratio <- manually_feature(fiducial_pt_list, test_idx))
  
  dat_test_selected_stand <- cbind(dat_test_selected,dat_test_double,dat_test_ratio)
  dat_test_selected_stand <- feature_normalization(dat_test_selected_stand)
  dat_test_selected_stand <- cbind(dat_test_selected_stand,dat_test$emotion_idx)
  colnames(dat_test_selected_stand)[dim(dat_test_selected_stand)[2]] <- "emotion_idx"
}

tm_feature_test_test <- NA
if(run.feature.test.test){
  test_test_idx = c(1:2500)
  ## This is the result from test
  feature_name <- c("point.7.to.point.21","point.10.to.point.13","point.10.to.point.33",
                    "point.11.to.point.49","point.12.to.point.55","point.14.to.point.18",
                    "point.23.to.point.50","point.34.to.point.46","point.50.to.point.62",
                    "point.59.to.point.62")
  
  ## Distance Feature
  tm_feature_test_test <- system.time(dat_test_test <- feature_train(fiducial_pt_list, test_test_idx))
  colnames(dat_test_test)<-make.names(colnames(dat_test_test),unique=T)
  dat_test_test_selected <- dat_test_test[,feature_name]
  
  ## Size Feature
  tm_feature_test_test <- tm_feature_test_test +
    system.time(dat_test_test_double <- feature_selection_size(dat_test_test_selected))
  
  ## Add manually selected feature
  tm_feature_test_test <- tm_feature_test_test + 
    system.time(dat_test_test_ratio <- manually_feature(fiducial_pt_list, test_test_idx))
  
  dat_test_selected_stand_test <- cbind(dat_test_test_selected,dat_test_test_double,
                                   dat_test_test_ratio)
  dat_test_selected_stand_test <- feature_normalization(dat_test_selected_stand_test)
  
}


##save(dat_train_selected_stand, file="../output/feature_train.RData")
## Because feature train takes over 10 hours, we do not knit this part. 
## The previous feature selection train is already included in the output file.
save(dat_test_selected_stand, file="../output/feature_test.RData")
##save(dat_test_selected_stand_test, file="../output/feature_test_test.RData")

```

### ### Step 4: Train a classification model with training features and responses

```{r}
load("../output/feature_train.RData")
dat_train_selected <- dat_train_selected_ratio_stand55
dat_test_selected <- dat_test_selected_stand
```

Call the train models and test models from library:

* 1. KNN 
* 2. LDA
* 3. SVM with radial kernel (improved model)
* 4. GBM with tree stumps (baseline Model)

#### 1. KNN

```{r model_setup, include=F}
#k = c(5, 10, 20, 30, 40, 45)
#model_labels = paste("KNN with K =", k)
```

* Do model selection by choosing among different values of training model parameters.
```{r run.cv=T, eval=F, include=F}

#source("../lib/cross_validation_knn.R")
#if(runcv){
#  err_cv <- matrix(0, nrow = length(k), ncol = 2)
#  for(i in 1:length(k)){
#    cat("k=", k[i], "\n")
#    err_cv[i,] <- cv.function(dat_train_selected, K, k[i])
#  save(err_cv, file="../output/err_cv.RData")
#  }
#}
```

* Choose the "best" parameter value
```{r best_model, include=FALSE} 
#if(run.cv){
#  model_best <- k[which.min(err_cv[,1])]
#  }
#par_best <- list(k = model_best)
```

* Train accuracy:
```{r, include=F}
#source("../lib/test_knn.R")

#if(run.test){
#  pred_train <- test(par_best$k, dat_train_selected)
#}

#accu <- mean(dat_train_selected$emotion_idx == pred_train)
#accu
```

* KNN: Run test on test images
```{r test_false, include=F}
#source("../lib/test_knn.R")
#tm_test=NA
#if(run.test){
#  tm_test <- system.time(pred <- test(par_best$k, dat_test_selected))
#}
```

* evaluation
```{r, include=F}
#accu <- mean(dat_test_selected$emotion_idx == pred)
#cat("The accuracy of model:", "is", accu*100, "%.\n")

#library(caret)
#confusionMatrix(pred, dat_test_selected$emotion_idx)
```

* Summarize Running Time
```{r running_time_false, include=F}
#cat("Time for testing model=", tm_test[1], "s \n")
```


#### 2. LDA

* Train the model with the entire training set using the selected model (model parameter) via cross-validation.
```{r final_train_lda}
source("../lib/train_lda.R")
tm_train=NA
tm_train <- system.time(fit_train <- train(dat_train_selected, par_best))
save(fit_train, file="../output/fit_train.RData")
```

* Train Accuracy:
```{r}
source("../lib/test_lda.R")
tm_test=NA
if(run.test){
  pred_train <- test(fit_train, dat_train_selected)
}

accu <- mean(dat_train_selected$emotion_idx == pred_train)
accu
```

* LDA: Run test on test images
```{r test_lda}
source("../lib/test_lda.R")
tm_test=NA
if(run.test){
  load(file="../output/fit_train.RData")
  tm_test <- system.time(pred <- test(fit_train, dat_test_selected))
}
```

* evaluation
```{r}
accu <- mean(dat_test_selected$emotion_idx == pred)
cat("The accuracy of model:", "is", accu*100, "%.\n")

library(caret)
confusionMatrix(pred, dat_test_selected$emotion_idx)
```

Note that the accuracy is not high but is better than that of ramdom guess(4.5%). 

* Summarize Running Time
Prediction performance matters, so does the running times for constructing features and for training the model, especially when the computation resource is limited. 
```{r running_time_lda}
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for testing model=", tm_test[1], "s \n")
```


#### 3. SVM (*improved model*)

* Tune the SVM model with cross-validation:
```{r}
## must have selected features first
tm_train=NA
tm_train <- system.time(tuned_parameters <- tune.svm(emotion_idx~., 
                                                     data = dat_train_selected, 
                                                     gamma = 10^(-5:-1), 
                                                     cost = c(30,35,40),
                                                     tunecontrol = tune.control(cross = 12)
                                                     ))
summary(tuned_parameters)
```

* Train the model
```{r final_train_svm}
source("../lib/train_svm.R")
par_best=NULL
fit_train_final_svm <- train(dat_train_selected, tuned_parameters$best.parameters)
save(fit_train_final_svm, file="../output/fit_train_final.RData")
```

* Train accuracy:
```{r}
source("../lib/test_svm.R")
load("../output/fit_train_final.RData")

if(run.test){
  pred_train <- test(fit_train_final_svm, dat_train_selected)
}

accu <- mean(dat_train_selected$emotion_idx == pred_train)
accu
```

* SVM: Run test on test images
```{r test_svm}
source("../lib/test_svm.R")
tm_test=NA
if(run.test){
  load(file="../output/fit_train.RData")
  tm_test <- system.time(pred <- test(fit_train_final_svm, dat_test_selected))
}
```

************ SVM: Run test_test on test images
```{r test_svm2}
source("../lib/test_svm.R")
tm_test=NA
if(run.test){
  load(file="../output/fit_train_final.RData")
  tm_test <- system.time(pred <- test(fit_train_final_svm, dat_test_selected))
}
```


* evaluation
```{r}
accu <- mean(dat_test_selected$emotion_idx == pred)
cat("The accuracy of model:", "is", accu*100, "%.\n")

library(caret)
confusionMatrix(pred, dat_test_selected$emotion_idx)
```

### Summarize Running Time
Prediction performance matters, so does the running times for constructing features and for training the model, especially when the computation resource is limited. 
```{r running_time_svm}
#cat("Time for constructing training features=", tm_feature_train[1], "s \n")
#cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for testing model=", tm_test[1], "s \n")
```

#### 4. GBM (*Baseline Model*)

* Tune GBM.
```{r}
hyper_grid <- expand.grid(
  shrinkage = c(.001, .01),
  interaction.depth = c(1, 3),
  n.minobsinnode = c(5, 10),
  bag.fraction = c(.65, .8), 
  optimal_trees = 0,               # a place to dump results
  min_RMSE = 0                     # a place to dump results
)

# randomize data
random_index <- sample(1:nrow(dat_train_selected), nrow(dat_train_selected))
random_train <- dat_train_selected[random_index, ]

# grid search 
for(i in 1:nrow(hyper_grid)) {
  
  # reproducibility
  set.seed(123)
  
  # train model
  gbm.tune <- gbm(
    formula =  emotion_idx~.,
    distribution = "multinomial",
    data = random_train,
    n.trees = 100,
    interaction.depth = hyper_grid$interaction.depth[i],
    shrinkage = hyper_grid$shrinkage[i],
    n.minobsinnode = hyper_grid$n.minobsinnode[i],
    bag.fraction = hyper_grid$bag.fraction[i],
    train.fraction = .75,
    n.cores = NULL, # will use all cores by default
    verbose = FALSE
  )
  
  # add min training error and trees to grid
  hyper_grid$optimal_trees[i] <- which.min(gbm.tune$valid.error)
  hyper_grid$min_RMSE[i] <- sqrt(min(gbm.tune$valid.error))
}

hyper_grid %>% 
  dplyr::arrange(min_RMSE) %>%
  head(10)
```

* Train the model with the entire training set using the selected model (model parameter) via cross-validation.
```{r final_train_gbm}
source("../lib/train_gbm.R")
tm_train=NA
tm_train <- system.time(fit_train_baseline <- train(dat_train_selected, par = NULL))
save(fit_train_baseline, file="../output/fit_train_baseline_final.RData")
```

* Train Error:
```{r}
source("../lib/test_gbm.R")
load("../output/fit_train_baseline_final.RData")

tm_test=NA
if(run.test){
  tm_test <- system.time(pred_train <- test(fit_train_baseline, dat_train_selected))
}

labels = colnames(pred_train)[apply(pred_train, 1, which.max)]
accu <- mean(dat_train_selected$emotion_idx == labels)
accu
```


* GBM: Run test on test images
```{r test_gbm}
source("../lib/test_gbm.R")
tm_test=NA
if(run.test){
  load(file="../output/fit_train.RData")
  tm_test <- system.time(pred <- test(fit_train_baseline, dat_test_selected))
}
```

* GBM: Run test_test on test images
```{r test_gbm2}
source("../lib/test_gbm.R")
tm_test_test=NA
if(run.feature.test.test){
  load(file="../output/fit_train_baseline_final.RData")
  tm_test <- system.time(pred <- test(fit_train_baseline, dat_test_selected))
}
```

* evaluation
```{r}
labels = colnames(pred)[apply(pred, 1, which.max)]
accu <- mean(dat_test_selected$emotion_idx == labels)
cat("The accuracy of model:", "is", accu*100, "%.\n")

library(caret)
confusionMatrix(as.factor(labels), dat_test_selected$emotion_idx)
```

###Reference
```{r, include=F}
## Test Test Procedure
load("../output/fiducial_pt_list_test.RData")


run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set


source("../lib/feature.R")
tm_feature_test_test <- NA
test_test_idx = c(1:2500)
## This is the result from test
feature_name <- c("point.7.to.point.21","point.10.to.point.13","point.10.to.point.33",
                  "point.11.to.point.49","point.12.to.point.55","point.14.to.point.18",
                  "point.23.to.point.50","point.34.to.point.46","point.50.to.point.62",
                  "point.59.to.point.62")


```

- Du, S., Tao, Y., & Martinez, A. M. (2014). Compound facial expressions of emotion. Proceedings of the National Academy of Sciences, 111(15), E1454-E1462.